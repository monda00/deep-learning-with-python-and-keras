# 気づき

## ３章：入門ニューラルネットワーク

- 損失関数は最小化する数量
- オプティマイザは更新する方法
- 正しい損失関数を選ぶ
  - 二値分類は交差エントロピー
  - 多クラス分類は多クラス交差エントロピー
  - 回帰問題は平均二乗誤差(mse)
  - 系列学習問題にはCTC
- 損失関数は複数設定できる
- ニューラルネットワークの入力になるようにテンソルに変換
  - リストをパディングして同じ長さに揃える
  - one-hotになるベクトルに変換
- one-hotエンコーディングは、カテゴリ値のデータで広く使われている
- 46種類のクラスを学習するには、16次元の空間では制限がきついかも？？
- categorical_crossentropyは２つの確率分布（ネットワークによって出力されるものと、真の分布）の距離を計測する
- ロジスティック回帰は回帰アルゴリズムではなく、分類アルゴリズム
- 異なる範囲の値をとる特徴量を入力とすると、学習が困難になる
  - 特徴量ごとの正規化が有効（特徴量の平均値を引き、標準偏差で割る）
  - テストデータの正規化は訓練データを使って計算する
- スカラー回帰は連続値を１つ予測する回帰
  - 最後の層を活性化関数を設定しないで、線形の層にする

# 疑問

- 層の数、ユニットの数、損失関数、活性化関数は全ての組み合わせを調べないとどれがいいのかわからない？

